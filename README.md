# Input Representation Ensemble Networks  
Problem Statement: We wish to see if we can identify an underlying separable space for objects given various input representations including but not limited to words, descriptions, images, and speech.  
Approach and Novelty: Existing methods for object classification or generation have purely one task in mind. Existing networks can be leveraged for classification through simple ensembles that weight probabilities of a given class. What we propose is building a generalized autoencoder which takes an optional set of inputs from different domains [words, descriptions, images] and create simple parallel network architecture resulting in a common latent space. The loss function to be used will aim to separate different classes in the latent space such that a [potentially linear] classifier can be created separately over the latent space for robust classification. Similarly it will minimize the distance between objects of the same class. The struggle will be handling the different inputs and ensuring that if multiple inputs are present it enhances the latent space but if inputs are missing the same embedding can be produced.   
